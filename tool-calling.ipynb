{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01bed5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-06 11:05:20,683 - INFO - Model initialized successfully\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "import re\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('langgraph_workflow.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# init model from ollama\n",
    "model = init_chat_model(\n",
    "    # \"ollama:gemma3:12b-it-qat\",\n",
    "    \"ollama:gemma3:4b\"\n",
    ")\n",
    "\n",
    "logger.info(\"Model initialized successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a8d62db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(location: str):\n",
    "    \"\"\"Returns weather info for a location.\n",
    "    \n",
    "    Args:\n",
    "        location (str): The location to get the weather for.\n",
    "\n",
    "    Returns:\n",
    "        str: A string describing the weather.\n",
    "\n",
    "    Example:\n",
    "        >>> get_weather(\"San Francisco\")\n",
    "    \"\"\"\n",
    "    if location.lower() in [\"sf\", \"san francisco\"]:\n",
    "        return \"It's 60 degrees and foggy.\"\n",
    "    return \"It's 90 degrees and sunny.\"\n",
    "\n",
    "# Available tools dictionary\n",
    "TOOLS = {\n",
    "    \"get_weather\": get_weather\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4938bf8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-06 10:56:54,073 - INFO - Tool description created:\n",
      "def get_weather(location: str):\n",
      "\"\"\"Returns weather info for a location.\n",
      "\n",
      "    Args:\n",
      "        location (str): The location to get the weather for.\n",
      "\n",
      "    Returns:\n",
      "        str: A string describing the weather.\n",
      "\n",
      "    Example:\n",
      "        >>> get_weather(\"San Francisco\")\n",
      "    \n",
      "\"\"\"\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "def create_tool_description(tools: dict):\n",
    "    \"\"\"Creates a string description of available tools that we can pass to the model.\n",
    "    \n",
    "    Includes name, description and usage information for each tool.\n",
    "    \"\"\"\n",
    "    \n",
    "    # for each tool, return its docstring\n",
    "    tool_descriptions = []\n",
    "    for tool_name, tool_func in tools.items():\n",
    "        signature = inspect.signature(tool_func)\n",
    "        docstring = tool_func.__doc__\n",
    "        tool_descriptions.append(f\"def {tool_name}{signature}:\\n\\\"\\\"\\\"{docstring}\\n\\\"\\\"\\\"\")\n",
    "    return \"\\n\".join(tool_descriptions)\n",
    "\n",
    "# test that it works\n",
    "tool_description = create_tool_description(TOOLS)\n",
    "logger.info(f\"Tool description created:\\n{tool_description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "683b353c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Instructions\n",
      "You are a helpful conversational AI assistant.\n",
      "At each turn, if you decide to invoke any of the function(s), it should be wrapped with ```tool_code```.\n",
      "The python methods described below are imported and available, you can only use defined methods.\n",
      "ONLY use the ```tool_code``` format when absolutely necessary to answer the user's question.\n",
      "The generated code should be readable and efficient. \n",
      "\n",
      "For questions that don't require any specific tools, just respond normally without tool calls.\n",
      "\n",
      "# Instructions for using tools:\n",
      "- Never use print statements. All tool outputs are automatically handled. Only use the tool call format as shown.\n",
      "- The response to a method will be wrapped in ```tool_output``` use it to call more tools or generate a helpful, friendly response.\n",
      "- When using a ```tool_call``` think step by step why and how it should be used. \n",
      "- All tools will directly output a string into the `tool_output` variable. \n",
      "\n",
      "The following Python methods are available:\n",
      "\n",
      "```python\n",
      "def get_weather(location: str):\n",
      "\"\"\"Returns weather info for a location.\n",
      "\n",
      "    Args:\n",
      "        location (str): The location to get the weather for.\n",
      "\n",
      "    Returns:\n",
      "        str: A string describing the weather.\n",
      "\n",
      "    Example:\n",
      "        >>> get_weather(\"San Francisco\")\n",
      "    \n",
      "\"\"\"\n",
      "```\n",
      "\n",
      "# Example usage of tools:\n",
      "You can use a tool like this:\n",
      "```tool_code\n",
      "my_tool(\"argument1\", \"argument2\")\n",
      "```\n",
      "- Where 'my_tool' is the name of the tool you want to call, and 'argument1', 'argument2' are the arguments you want to pass to the tool.\n",
      "\n",
      "# Bad example of tool usage:\n",
      "```tool_code\n",
      "result = my_tool(\"argument1\", \"argument2\")\n",
      "print(result)\n",
      "```\n",
      "- This code will cause an error because the tool output is not being used correctly.\n",
      "\n",
      "```tool_code\n",
      "print(my_tool(\"argument1\", \"argument2\"))\n",
      "```\n",
      "- This code will cause an error because the tool output is not being used correctly.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ensure you do not include any \".\" in the prompt - you will get errors during the function call!S\n",
    "instruction_prompt = f'''\n",
    "# Instructions\n",
    "You are a helpful conversational AI assistant.\n",
    "At each turn, if you decide to invoke any of the function(s), it should be wrapped with ```tool_code```.\n",
    "The python methods described below are imported and available, you can only use defined methods.\n",
    "ONLY use the ```tool_code``` format when absolutely necessary to answer the user's question.\n",
    "The generated code should be readable and efficient. \n",
    "\n",
    "For questions that don't require any specific tools, just respond normally without tool calls.\n",
    "\n",
    "# Instructions for using tools:\n",
    "- Never use print statements. All tool outputs are automatically handled. Only use the tool call format as shown.\n",
    "- The response to a method will be wrapped in ```tool_output``` use it to call more tools or generate a helpful, friendly response.\n",
    "- When using a ```tool_call``` think step by step why and how it should be used. \n",
    "- All tools will directly output a string into the `tool_output` variable. \n",
    "\n",
    "The following Python methods are available:\n",
    "\n",
    "```python\n",
    "{tool_description}\n",
    "```\n",
    "\n",
    "# Example usage of tools:\n",
    "You can use a tool like this:\n",
    "```tool_code\n",
    "my_tool(\"argument1\", \"argument2\")\n",
    "```\n",
    "- Where 'my_tool' is the name of the tool you want to call, and 'argument1', 'argument2' are the arguments you want to pass to the tool.\n",
    "\n",
    "# Bad example of tool usage:\n",
    "```tool_code\n",
    "result = my_tool(\"argument1\", \"argument2\")\n",
    "print(result)\n",
    "```\n",
    "- This code will cause an error because the tool output is not being used correctly.\n",
    "\n",
    "```tool_code\n",
    "print(my_tool(\"argument1\", \"argument2\"))\n",
    "```\n",
    "- This code will cause an error because the tool output is not being used correctly.\n",
    "'''\n",
    "\n",
    "print(instruction_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9044f492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tool_calls(text):\n",
    "    \"\"\"Extract tool calls from model output using regex parsing.\"\"\"\n",
    "    logger.info(f\"[TOOL_PARSER] Starting tool extraction from text: {text[:500]}...\")\n",
    "    \n",
    "    pattern = r\"```tool_code\\s*(.*?)\\s*```\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        code = match.group(1).strip()\n",
    "        logger.info(f\"[TOOL_PARSER] Found tool code: {code}\")\n",
    "        \n",
    "        try:\n",
    "            logger.info(f\"[TOOL_PARSER] Attempting to execute: {code}\")\n",
    "            logger.info(f\"[TOOL_PARSER] Available tools: {list(TOOLS.keys())}\")\n",
    "            \n",
    "            # Execute the tool call safely\n",
    "            result = eval(code, {\"__builtins__\": {}}, TOOLS)\n",
    "            logger.info(f\"[TOOL_PARSER] Tool execution successful: {result}\")\n",
    "            \n",
    "            return f'```tool_output\\n{result}\\n```'\n",
    "        except Exception as e:\n",
    "            logger.error(f\"[TOOL_PARSER] Tool execution failed: {str(e)}\")\n",
    "            logger.error(f\"[TOOL_PARSER] Error type: {type(e).__name__}\")\n",
    "            logger.error(f\"[TOOL_PARSER] Code that failed: {code}\")\n",
    "            return f'```tool_output\\nError: {str(e)}\\n```'\n",
    "    else:\n",
    "        logger.info(\"[TOOL_PARSER] No tool_code blocks found in text\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3c48d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def react_agent(state: MessagesState):\n",
    "    \"\"\"Single ReAct agent that can generate responses and execute tools in a loop.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    logger.info(f\"[REACT] Processing {len(messages)} messages\")\n",
    "    \n",
    "    # Always include the system prompt for tool instructions\n",
    "    system_prompt = instruction_prompt\n",
    "    \n",
    "    # Build conversation with system prompt\n",
    "    conversation = [{\"role\": \"system\", \"content\": system_prompt}] + messages\n",
    "    \n",
    "    # Generate response\n",
    "    response = model.invoke(conversation)\n",
    "    logger.info(f\"[REACT] Model response: {response.content[:200]}...\")\n",
    "    \n",
    "    # Check if response contains tool calls\n",
    "    if '```tool_code' in str(response.content):\n",
    "        logger.info(\"[REACT] Tool code detected - executing tools\")\n",
    "        \n",
    "        # Execute the tool call\n",
    "        tool_output = extract_tool_calls(response.content)\n",
    "        \n",
    "        if tool_output:\n",
    "            logger.info(f\"[REACT] Tool execution result: {tool_output}\")\n",
    "            \n",
    "            # Extract the result from tool_output\n",
    "            result_match = re.search(r'```tool_output\\n(.*?)\\n```', tool_output, re.DOTALL)\n",
    "            if result_match:\n",
    "                clean_result = result_match.group(1).strip()\n",
    "                logger.info(f\"[REACT] Clean result: {clean_result}\")\n",
    "                \n",
    "                # Create a new response incorporating the tool result\n",
    "                final_response_prompt = f\"\"\"Based on the tool result: {clean_result}\n",
    "                \n",
    "Please provide a helpful, natural response to the user incorporating this information. \n",
    "Do not include any tool code or technical details, just a conversational answer.\"\"\"\n",
    "                \n",
    "                # Generate final response with tool result\n",
    "                final_conversation = [\n",
    "                    {\"role\": \"system\", \"content\": final_response_prompt},\n",
    "                    {\"role\": \"user\", \"content\": messages[-1].content}\n",
    "                ]\n",
    "                \n",
    "                final_response = model.invoke(final_conversation)\n",
    "                logger.info(f\"[REACT] Final response with tool result: {final_response.content}\")\n",
    "                \n",
    "                return {\"messages\": [final_response]}\n",
    "    \n",
    "    # No tool calls needed, return the response as-is\n",
    "    logger.info(\"[REACT] No tool calls detected - returning response\")\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_continue_react(state: MessagesState):\n",
    "    \"\"\"Always end after the react agent processes the input.\"\"\"\n",
    "    return \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "023c9dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified ReAct graph setup \n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"react\", react_agent)\n",
    "\n",
    "builder.add_edge(START, \"react\")\n",
    "builder.add_edge(\"react\", END)\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d23aa2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced utils for better debugging\n",
    "def print_conversation(result):\n",
    "    print(\"=== CONVERSATION FLOW ===\")\n",
    "    messages = result[\"messages\"]\n",
    "    \n",
    "    for i, message in enumerate(messages):\n",
    "        print(f\"\\n--- Message {i+1} ---\")\n",
    "        print(f\"Type: {type(message).__name__}\")\n",
    "        print(f\"Content: {message.content}\")\n",
    "        \n",
    "        # Check if this message contains a tool call\n",
    "        if '```tool_code' in str(message.content):\n",
    "            print(\"üîß TOOL CALL DETECTED\")\n",
    "            \n",
    "            # Extract the tool code for debugging\n",
    "            pattern = r\"```tool_code\\s*(.*?)\\s*```\"\n",
    "            match = re.search(pattern, message.content, re.DOTALL)\n",
    "            if match:\n",
    "                code = match.group(1).strip()\n",
    "                print(f\"üìù Tool Code: {code}\")\n",
    "                \n",
    "                # Try to execute and show result\n",
    "                tool_output = extract_tool_calls(message.content)\n",
    "                if tool_output:\n",
    "                    print(f\"üîß Tool Result: {tool_output}\")\n",
    "                else:\n",
    "                    print(\"‚ùå No tool output generated\")\n",
    "            else:\n",
    "                print(\"‚ùå Could not extract tool code\")\n",
    "        \n",
    "        # Show if this is a tool output\n",
    "        if '```tool_output' in str(message.content):\n",
    "            print(\"üìä TOOL OUTPUT DETECTED\")\n",
    "            \n",
    "            # Extract the tool output for debugging\n",
    "            pattern = r\"```tool_output\\n(.*?)\\n```\"\n",
    "            match = re.search(pattern, message.content, re.DOTALL)\n",
    "            if match:\n",
    "                output = match.group(1).strip()\n",
    "                print(f\"üìã Output: {output}\")\n",
    "        \n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0f59c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-06 11:05:27,611 - INFO - [REACT] Processing 2 messages\n",
      "2025-07-06 11:05:29,750 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "2025-07-06 11:05:30,060 - INFO - [REACT] Model response: Hi Barry! My name is Tim. It‚Äôs nice to meet you!\n",
      "...\n",
      "2025-07-06 11:05:30,062 - INFO - [REACT] No tool calls detected - returning response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CONVERSATION FLOW ===\n",
      "\n",
      "--- Message 1 ---\n",
      "Type: SystemMessage\n",
      "Content: You are a helpful assistant named Tim\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Message 2 ---\n",
      "Type: HumanMessage\n",
      "Content: What is your name? I am barry!\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Message 3 ---\n",
      "Type: AIMessage\n",
      "Content: Hi Barry! My name is Tim. It‚Äôs nice to meet you!\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#excecute graph - test that chat history works\n",
    "input_prompt = \"You are a helpful assistant named Tim\"\n",
    "query = \"What is your name? I am barry!\"\n",
    "messages = [\n",
    "    SystemMessage(content=input_prompt),\n",
    "    HumanMessage(content=query)\n",
    "]\n",
    "state : MessagesState = {\"messages\": messages}\n",
    "result = graph.invoke({\"messages\": state[\"messages\"]})\n",
    "print_conversation(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5fb336d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-06 11:13:30,629 - INFO - [REACT] Processing 2 messages\n",
      "2025-07-06 11:13:31,454 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "2025-07-06 11:13:31,744 - INFO - [REACT] Model response: ```tool_code\n",
      "get_weather(location=\"San Francisco\")\n",
      "```...\n",
      "2025-07-06 11:13:31,745 - INFO - [REACT] Tool code detected - executing tools\n",
      "2025-07-06 11:13:31,745 - INFO - [TOOL_PARSER] Starting tool extraction from text: ```tool_code\n",
      "get_weather(location=\"San Francisco\")\n",
      "```...\n",
      "2025-07-06 11:13:31,746 - INFO - [TOOL_PARSER] Found tool code: get_weather(location=\"San Francisco\")\n",
      "2025-07-06 11:13:31,747 - INFO - [TOOL_PARSER] Attempting to execute: get_weather(location=\"San Francisco\")\n",
      "2025-07-06 11:13:31,747 - INFO - [TOOL_PARSER] Available tools: ['get_weather']\n",
      "2025-07-06 11:13:31,748 - INFO - [TOOL_PARSER] Tool execution successful: It's 60 degrees and foggy.\n",
      "2025-07-06 11:13:31,748 - INFO - [REACT] Tool execution result: ```tool_output\n",
      "It's 60 degrees and foggy.\n",
      "```\n",
      "2025-07-06 11:13:31,749 - INFO - [REACT] Clean result: It's 60 degrees and foggy.\n",
      "2025-07-06 11:13:31,918 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "2025-07-06 11:13:32,558 - INFO - [REACT] Final response with tool result: Okay, it‚Äôs looking pretty hazy out there ‚Äì it‚Äôs 60 degrees and foggy in San Francisco today. A bit chilly and mysterious, isn‚Äôt it?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CONVERSATION FLOW ===\n",
      "\n",
      "--- Message 1 ---\n",
      "Type: SystemMessage\n",
      "Content: You are a helpful assistant named Tim\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Message 2 ---\n",
      "Type: HumanMessage\n",
      "Content: What is the weather in San Francisco?\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Message 3 ---\n",
      "Type: AIMessage\n",
      "Content: Okay, it‚Äôs looking pretty hazy out there ‚Äì it‚Äôs 60 degrees and foggy in San Francisco today. A bit chilly and mysterious, isn‚Äôt it?\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test the simplified ReAct graph with weather query\n",
    "input_prompt = \"You are a helpful assistant named Tim\"\n",
    "query = \"What is the weather in San Francisco?\"\n",
    "messages = [\n",
    "    SystemMessage(content=input_prompt),\n",
    "    HumanMessage(content=query)\n",
    "]\n",
    "state : MessagesState = {\"messages\": messages}\n",
    "result = graph.invoke({\"messages\": state[\"messages\"]})\n",
    "print_conversation(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
