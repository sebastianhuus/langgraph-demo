{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "01bed5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "import re\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('langgraph_workflow.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "afc8f109",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from enum import Enum\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "\n",
    "class Models(Enum):\n",
    "    GEMMA3_12B_IT_QAT = \"gemma3:12b-it-qat\"\n",
    "    GEMMA3_4B = \"gemma3:4b\"\n",
    "\n",
    "    # return value of model when fetched\n",
    "    def __str__(self):\n",
    "        return self.value\n",
    "\n",
    "def init_ollama_chat_model(model_name: Models):\n",
    "    \"\"\"\n",
    "    Initialize the chat model from Ollama.\n",
    "    \"\"\"\n",
    "    ollama_model_name = f\"ollama:{model_name.value}\"\n",
    "\n",
    "    try:\n",
    "        model : BaseChatModel = init_chat_model(ollama_model_name)\n",
    "        logger.info(f\"Model {model} initialized successfully.\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to initialize model {ollama_model_name}: {e}\")\n",
    "        raise\n",
    "\n",
    "# init model from ollama\n",
    "model = init_ollama_chat_model(\n",
    "    #Models.GEMMA3_12B_IT_QAT\n",
    "    Models.GEMMA3_4B\n",
    ")\n",
    "\n",
    "logger.info(\"Model initialized successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9a8d62db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(location: str):\n",
    "    \"\"\"Returns weather info for a location.\n",
    "    \n",
    "    Args:\n",
    "        location (str): The location to get the weather for.\n",
    "\n",
    "    Returns:\n",
    "        str: A string describing the weather.\n",
    "\n",
    "    Example:\n",
    "        >>> get_weather(\"San Francisco\")\n",
    "    \"\"\"\n",
    "    if location.lower() in [\"sf\", \"san francisco\"]:\n",
    "        return \"It's 60 degrees and foggy.\"\n",
    "    return \"It's 90 degrees and sunny.\"\n",
    "\n",
    "# Available tools dictionary\n",
    "TOOLS = {\n",
    "    \"get_weather\": get_weather\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4938bf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "def create_tool_description(tools: dict):\n",
    "    \"\"\"Creates a string description of available tools that we can pass to the model.\n",
    "    \n",
    "    Includes name, description and usage information for each tool.\n",
    "    \"\"\"\n",
    "    \n",
    "    # for each tool, return its docstring\n",
    "    tool_descriptions = []\n",
    "    for tool_name, tool_func in tools.items():\n",
    "        signature = inspect.signature(tool_func)\n",
    "        docstring = tool_func.__doc__\n",
    "        tool_descriptions.append(f\"def {tool_name}{signature}:\\n\\\"\\\"\\\"{docstring}\\n\\\"\\\"\\\"\")\n",
    "    return \"\\n\".join(tool_descriptions)\n",
    "\n",
    "# test that it works\n",
    "tool_description = create_tool_description(TOOLS)\n",
    "logger.info(f\"Tool description created:\\n{tool_description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "683b353c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Instructions\n",
      "You are a helpful conversational AI assistant.\n",
      "At each turn, if you decide to invoke any of the function(s), it should be wrapped with ```tool_code```.\n",
      "The python methods described below are imported and available, you can only use defined methods.\n",
      "ONLY use the ```tool_code``` format when absolutely necessary to answer the user's question.\n",
      "The generated code should be readable and efficient. \n",
      "\n",
      "For questions that don't require any specific tools, just respond normally without tool calls.\n",
      "\n",
      "# Instructions for using tools:\n",
      "- Never use print statements. All tool outputs are automatically handled. Only use the tool call format as shown.\n",
      "- The response to a method will be wrapped in ```tool_output``` use it to call more tools or generate a helpful, friendly response.\n",
      "- When using a ```tool_call``` think step by step why and how it should be used. \n",
      "- All tools will directly output a string into the `tool_output` variable. \n",
      "\n",
      "The following Python methods are available:\n",
      "\n",
      "```python\n",
      "def get_weather(location: str):\n",
      "\"\"\"Returns weather info for a location.\n",
      "\n",
      "    Args:\n",
      "        location (str): The location to get the weather for.\n",
      "\n",
      "    Returns:\n",
      "        str: A string describing the weather.\n",
      "\n",
      "    Example:\n",
      "        >>> get_weather(\"San Francisco\")\n",
      "    \n",
      "\"\"\"\n",
      "```\n",
      "\n",
      "# Example usage of tools:\n",
      "You can use a tool like this:\n",
      "```tool_code\n",
      "my_tool(\"argument1\", \"argument2\")\n",
      "```\n",
      "- Where 'my_tool' is the name of the tool you want to call, and 'argument1', 'argument2' are the arguments you want to pass to the tool.\n",
      "\n",
      "# Bad example of tool usage:\n",
      "```tool_code\n",
      "result = my_tool(\"argument1\", \"argument2\")\n",
      "print(result)\n",
      "```\n",
      "- This code will cause an error because the tool output is not being used correctly.\n",
      "\n",
      "```tool_code\n",
      "print(my_tool(\"argument1\", \"argument2\"))\n",
      "```\n",
      "- This code will cause an error because the tool output is not being used correctly.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ensure you do not include any \".\" in the prompt - you will get errors during the function call!S\n",
    "instruction_prompt = f'''\n",
    "# Instructions\n",
    "You are a helpful conversational AI assistant.\n",
    "At each turn, if you decide to invoke any of the function(s), it should be wrapped with ```tool_code```.\n",
    "The python methods described below are imported and available, you can only use defined methods.\n",
    "ONLY use the ```tool_code``` format when absolutely necessary to answer the user's question.\n",
    "The generated code should be readable and efficient. \n",
    "\n",
    "For questions that don't require any specific tools, just respond normally without tool calls.\n",
    "\n",
    "# Instructions for using tools:\n",
    "- Never use print statements. All tool outputs are automatically handled. Only use the tool call format as shown.\n",
    "- The response to a method will be wrapped in ```tool_output``` use it to call more tools or generate a helpful, friendly response.\n",
    "- When using a ```tool_call``` think step by step why and how it should be used. \n",
    "- All tools will directly output a string into the `tool_output` variable. \n",
    "\n",
    "The following Python methods are available:\n",
    "\n",
    "```python\n",
    "{tool_description}\n",
    "```\n",
    "\n",
    "# Example usage of tools:\n",
    "You can use a tool like this:\n",
    "```tool_code\n",
    "my_tool(\"argument1\", \"argument2\")\n",
    "```\n",
    "- Where 'my_tool' is the name of the tool you want to call, and 'argument1', 'argument2' are the arguments you want to pass to the tool.\n",
    "\n",
    "# Bad example of tool usage:\n",
    "```tool_code\n",
    "result = my_tool(\"argument1\", \"argument2\")\n",
    "print(result)\n",
    "```\n",
    "- This code will cause an error because the tool output is not being used correctly.\n",
    "\n",
    "```tool_code\n",
    "print(my_tool(\"argument1\", \"argument2\"))\n",
    "```\n",
    "- This code will cause an error because the tool output is not being used correctly.\n",
    "'''\n",
    "\n",
    "print(instruction_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9044f492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tool_calls(text):\n",
    "    \"\"\"Extract tool calls from model output using regex parsing.\"\"\"\n",
    "    logger.info(f\"[TOOL_PARSER] Starting tool extraction from text: {text[:500]}...\")\n",
    "    \n",
    "    pattern = r\"```tool_code\\s*(.*?)\\s*```\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        code = match.group(1).strip()\n",
    "        logger.info(f\"[TOOL_PARSER] Found tool code: {code}\")\n",
    "        \n",
    "        try:\n",
    "            logger.info(f\"[TOOL_PARSER] Attempting to execute: {code}\")\n",
    "            logger.info(f\"[TOOL_PARSER] Available tools: {list(TOOLS.keys())}\")\n",
    "            \n",
    "            # Execute the tool call safely\n",
    "            result = eval(code, {\"__builtins__\": {}}, TOOLS)\n",
    "            logger.info(f\"[TOOL_PARSER] Tool execution successful: {result}\")\n",
    "            \n",
    "            return f'```tool_output\\n{result}\\n```'\n",
    "        except Exception as e:\n",
    "            logger.error(f\"[TOOL_PARSER] Tool execution failed: {str(e)}\")\n",
    "            logger.error(f\"[TOOL_PARSER] Error type: {type(e).__name__}\")\n",
    "            logger.error(f\"[TOOL_PARSER] Code that failed: {code}\")\n",
    "            return f'```tool_output\\nError: {str(e)}\\n```'\n",
    "    else:\n",
    "        logger.info(\"[TOOL_PARSER] No tool_code blocks found in text\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c3c48d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def react_agent(state: MessagesState):\n",
    "    \"\"\"Single ReAct agent that can generate responses and execute tools in a loop.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    logger.info(f\"[REACT] Processing {len(messages)} messages\")\n",
    "    \n",
    "    # Always include the system prompt for tool instructions\n",
    "    system_prompt = instruction_prompt\n",
    "    \n",
    "    # Build conversation with system prompt\n",
    "    conversation = [{\"role\": \"system\", \"content\": system_prompt}] + messages\n",
    "    \n",
    "    # Generate response\n",
    "    response = model.invoke(conversation)\n",
    "    logger.info(f\"[REACT] Model response: {response.content[:200]}...\")\n",
    "    \n",
    "    # Check if response contains tool calls\n",
    "    if '```tool_code' in str(response.content):\n",
    "        logger.info(\"[REACT] Tool code detected - executing tools\")\n",
    "        \n",
    "        # Execute the tool call\n",
    "        tool_output = extract_tool_calls(response.content)\n",
    "        \n",
    "        if tool_output:\n",
    "            logger.info(f\"[REACT] Tool execution result: {tool_output}\")\n",
    "            \n",
    "            # Extract the result from tool_output\n",
    "            result_match = re.search(r'```tool_output\\n(.*?)\\n```', tool_output, re.DOTALL)\n",
    "            if result_match:\n",
    "                clean_result = result_match.group(1).strip()\n",
    "                logger.info(f\"[REACT] Clean result: {clean_result}\")\n",
    "                \n",
    "                # Create a new response incorporating the tool result\n",
    "                final_response_prompt = f\"\"\"Based on the tool result: {clean_result}\n",
    "                \n",
    "Please provide a helpful, natural response to the user incorporating this information. \n",
    "Do not include any tool code or technical details, just a conversational answer.\"\"\"\n",
    "                \n",
    "                # Generate final response with tool result\n",
    "                final_conversation = [\n",
    "                    {\"role\": \"system\", \"content\": final_response_prompt},\n",
    "                    {\"role\": \"user\", \"content\": messages[-1].content}\n",
    "                ]\n",
    "                \n",
    "                final_response = model.invoke(final_conversation)\n",
    "                logger.info(f\"[REACT] Final response with tool result: {final_response.content}\")\n",
    "                \n",
    "                return {\"messages\": [final_response]}\n",
    "    \n",
    "    # No tool calls needed, return the response as-is\n",
    "    logger.info(\"[REACT] No tool calls detected - returning response\")\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_continue_react(state: MessagesState):\n",
    "    \"\"\"Always end after the react agent processes the input.\"\"\"\n",
    "    return \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "023c9dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified ReAct graph setup \n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"react\", react_agent)\n",
    "\n",
    "builder.add_edge(START, \"react\")\n",
    "builder.add_edge(\"react\", END)\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d23aa2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced utils for better debugging\n",
    "def print_conversation(result):\n",
    "    print(\"=== CONVERSATION FLOW ===\")\n",
    "    messages = result[\"messages\"]\n",
    "    \n",
    "    for i, message in enumerate(messages):\n",
    "        print(f\"\\n--- Message {i+1} ---\")\n",
    "        print(f\"Type: {type(message).__name__}\")\n",
    "        print(f\"Content: {message.content}\")\n",
    "        \n",
    "        # Check if this message contains a tool call\n",
    "        if '```tool_code' in str(message.content):\n",
    "            print(\"üîß TOOL CALL DETECTED\")\n",
    "            \n",
    "            # Extract the tool code for debugging\n",
    "            pattern = r\"```tool_code\\s*(.*?)\\s*```\"\n",
    "            match = re.search(pattern, message.content, re.DOTALL)\n",
    "            if match:\n",
    "                code = match.group(1).strip()\n",
    "                print(f\"üìù Tool Code: {code}\")\n",
    "                \n",
    "                # Try to execute and show result\n",
    "                tool_output = extract_tool_calls(message.content)\n",
    "                if tool_output:\n",
    "                    print(f\"üîß Tool Result: {tool_output}\")\n",
    "                else:\n",
    "                    print(\"‚ùå No tool output generated\")\n",
    "            else:\n",
    "                print(\"‚ùå Could not extract tool code\")\n",
    "        \n",
    "        # Show if this is a tool output\n",
    "        if '```tool_output' in str(message.content):\n",
    "            print(\"üìä TOOL OUTPUT DETECTED\")\n",
    "            \n",
    "            # Extract the tool output for debugging\n",
    "            pattern = r\"```tool_output\\n(.*?)\\n```\"\n",
    "            match = re.search(pattern, message.content, re.DOTALL)\n",
    "            if match:\n",
    "                output = match.group(1).strip()\n",
    "                print(f\"üìã Output: {output}\")\n",
    "        \n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f0f59c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CONVERSATION FLOW ===\n",
      "\n",
      "--- Message 1 ---\n",
      "Type: SystemMessage\n",
      "Content: You are a helpful assistant named Tim\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Message 2 ---\n",
      "Type: HumanMessage\n",
      "Content: What is your name? I am barry!\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Message 3 ---\n",
      "Type: AIMessage\n",
      "Content: Hi Barry, my name is Tim! It's nice to meet you.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#excecute graph - test that chat history works\n",
    "input_prompt = \"You are a helpful assistant named Tim\"\n",
    "query = \"What is your name? I am barry!\"\n",
    "messages = [\n",
    "    SystemMessage(content=input_prompt),\n",
    "    HumanMessage(content=query)\n",
    "]\n",
    "state : MessagesState = {\"messages\": messages}\n",
    "result = graph.invoke({\"messages\": state[\"messages\"]})\n",
    "print_conversation(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f5fb336d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CONVERSATION FLOW ===\n",
      "\n",
      "--- Message 1 ---\n",
      "Type: SystemMessage\n",
      "Content: You are a helpful assistant named Tim\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Message 2 ---\n",
      "Type: HumanMessage\n",
      "Content: What is the weather in San Francisco?\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Message 3 ---\n",
      "Type: AIMessage\n",
      "Content: It‚Äôs 60 degrees and quite foggy here in San Francisco today. It‚Äôs a really soft, hazy kind of day!\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test the simplified ReAct graph with weather query\n",
    "input_prompt = \"You are a helpful assistant named Tim\"\n",
    "query = \"What is the weather in San Francisco?\"\n",
    "messages = [\n",
    "    SystemMessage(content=input_prompt),\n",
    "    HumanMessage(content=query)\n",
    "]\n",
    "state : MessagesState = {\"messages\": messages}\n",
    "result = graph.invoke({\"messages\": state[\"messages\"]})\n",
    "print_conversation(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "54c765f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool output found in message: It‚Äôs looking pretty foggy and cool in San Francisco ‚Äì it‚Äôs 60 degrees right now! You‚Äôll definitely want a jacket.\n",
      "Tool output found in message: It‚Äôs a really beautiful, but a bit mysterious day in San Francisco! It‚Äôs 60 degrees and quite foggy ‚Äì you‚Äôll definitely want a jacket and maybe some sunglasses!\n",
      "Tool output found in message: It‚Äôs 60 degrees and quite foggy here in San Francisco right now. A bit chilly and misty ‚Äì perfect for a cozy day!\n",
      "Tool output found in message: It‚Äôs looking pretty foggy and cool here in San Francisco ‚Äì it‚Äôs 60 degrees right now. You‚Äôll definitely want a jacket!\n",
      "Tool output found in message: Okay, it's looking pretty foggy and cool here in San Francisco ‚Äì it‚Äôs 60 degrees right now. You'll definitely want a jacket!\n",
      "Tool output found in message: It's looking pretty foggy and cool here in San Francisco ‚Äì it's 60 degrees right now! You'll definitely want a jacket.\n",
      "Tool output found in message: It‚Äôs looking pretty foggy and cool in San Francisco ‚Äì about 60 degrees today. You might want a jacket!\n",
      "Tool output found in message: It‚Äôs a really beautiful, but a bit mysterious, day in San Francisco! It‚Äôs 60 degrees and pretty foggy ‚Äì you‚Äôll want a jacket and maybe some sunglasses to deal with the haze.\n",
      "Tool output found in message: It‚Äôs looking pretty foggy and cool here in San Francisco ‚Äì it‚Äôs currently 60 degrees. You‚Äôll definitely want a jacket!\n",
      "Tool output found in message: It‚Äôs 60 degrees and quite foggy here in San Francisco right now. A bit chilly and mysterious, isn‚Äôt it?\n",
      "==============================\n",
      "Tests completed: 10/10 successful\n",
      "Success rate: 100.00%\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# Disable logging for this cell   \n",
    "import logging                    \n",
    "logging.disable(logging.CRITICAL) \n",
    "\n",
    "def test():\n",
    "    # Test the simplified ReAct graph with weather query\n",
    "    input_prompt = \"You are a helpful assistant named Tim\"\n",
    "    query = \"What is the weather in San Francisco?\"\n",
    "    messages = [\n",
    "        SystemMessage(content=input_prompt),\n",
    "        HumanMessage(content=query)\n",
    "    ]\n",
    "    state : MessagesState = {\"messages\": messages}\n",
    "    result = graph.invoke({\"messages\": state[\"messages\"]})\n",
    "    return result\n",
    "\n",
    "def analyze_results(result):\n",
    "    messages = result[\"messages\"]\n",
    "\n",
    "    # verify llm output a correct answer\n",
    "    llm_output_is_correct = False\n",
    "\n",
    "    ai_response = messages[-1]\n",
    "    content = ai_response.content\n",
    "\n",
    "    if \"60 degrees\" in content or \"foggy\" in content:\n",
    "        llm_output_is_correct = True\n",
    "        print(f\"Tool output found in message: {content}\")\n",
    "    else:\n",
    "        print(f\"Tool output NOT found in message: {content}\")\n",
    "\n",
    "    if llm_output_is_correct:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def run_tests():\n",
    "    success_count = 0\n",
    "    total_tests = 10\n",
    "\n",
    "    for i in range(total_tests):\n",
    "        result = test()\n",
    "        success = analyze_results(result)\n",
    "        if success:\n",
    "            success_count += 1\n",
    "\n",
    "    print(\"=\"* 30)\n",
    "    print(f\"Tests completed: {success_count}/{total_tests} successful\")\n",
    "    print(\"Success rate: {:.2f}%\".format((success_count / total_tests) * 100))\n",
    "    print(\"=\"* 30)\n",
    "\n",
    "run_tests()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
